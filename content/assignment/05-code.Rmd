---
# title: "Práctica 5. Regresión múltiple 1 "
subtitle: "Estadistica Multivariada - Sociología FACSO Universidad de Chile"
author: "Valentina Andrade"
# linktitle: "Práctica 5: Regresión múltiple 1"
date: "2020-06-22"
class_date: "2020-06-22"
citeproc: false
bibliography: ../../static/bib/references.bib
csl: ../../static/bib/chicago-syllabus-no-bib.csl
output:
  blogdown::html_page:
    template: ../../pandoc/toc-title_html.template
    toc: true
    highlight: tango
    number_sections: FALSE
menu:
  class:
    parent: Practicas
    weight: 1
type: docs
weight: 1
editor_options:
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(cache=FALSE, warnings=FALSE, message=FALSE)
knitr::opts_knit$set(root.dir ="../../")

Sys.setlocale("LC_ALL", "ES_ES.UTF-8")
```

```{r klippy, echo=FALSE, include=TRUE}
klippy::klippy(position = c('bottom', 'right')) # chunks con botón de copiar
```

# Objetivo de la práctica

En esta práctica nos enfocaremos en el concepto de regresión múltiple, a partir de la incorporación de dos o más predictores en el modelo. Para ello utilizaremos el ejemplo 3.1 de Wooldridge (2010) cap. 3 (Análisis de regresion múltiple) (p.68-80) sobre las **determinantes del promedio en la universidad**.

## Librerías

```{r, warning= FALSE}
pacman::p_load(ggpubr, #graficos
               dplyr, #manipulacion de datos
               sjPlot, #tablas
               gridExtra, #unir graficos
               texreg, #mostrar regresion multiple
               summarytools, #estadisticos descriptivos
               wooldridge) #paquete con los ejemplos del libro

```


## Datos

Los datos a utilizar corresponden a la base de datos **gpa1** que incluye una muestra de 141 estudiantes de una universidad. La base contiene vaiables
- [$colGPA$]: promedio general de calificaciones de la universidad, en escala de 0 a 4 puntos.
- [$hsGPA$]: promedio general de calificaciones en la enseñanza media, en escala de 0 a 4 puntos
- [$ACT$]: puntaje en el examen de admisión a la universidad, que va de 16 a 33 puntos
Primero, se cargará la base de datos que contiene la librería `wooldridge` y se seleccionarán las variables señaladas
```{r}
data('gpa1') # Cargar base de datos
gpa1 <- dplyr::select(gpa1, colGPA, hsGPA, ACT) #Seleccion de variables
```
## Explorar base de datos

A partir de la siguiente tabla se obtienen estadísticos descriptivos que luego serán relevantes para la interpretación de nuestros modelos.

```{r}
view(dfSummary(gpa1, headings = FALSE, method = 'render'))
```

## Modelo de regresión simple

Si solo nos centramos en el análisis de regresión simple, intuitivamente partiremos por predecir las calificaciones de la universidad a partir del puntaje obtenido en la prueba de admisión a esta. Formalmente

$$\widehat{colGPA} = b_{0} +b_{1}ACT $$
```{r}
col_actmodel<-lm(colGPA ~ ACT, data=gpa1) #Crear regresion simple
summary(col_actmodel)
```

En formato publicable:

```{r}
sjPlot::tab_model(col_actmodel, show.ci=FALSE) #Tabla resumen de resultados
```

En consecuencia, nuestro modelo que relaciona el promedio de calificaciones en la universidad solo con el puntaje obtenido en el examen de admisión señala que por cada punto adicional que se obtiene en la prueba de admisión, el promedio de la universidad aumenta en 0.027 (aproximado en la tabla de sjPlot a 0.03) puntos promedio.

$$\widehat{colGPA} = 2.40 +0.0271ACT $$

Ahora bien, si miramos nuestro $R^2$ notaremos que $ACT$ solo explica en un 4.3% la varianza de $colGPA$. Por ello, incluiremos el promedio de las calificaciones de la enseñanza media ($hsGPA$) para intentar predecir mejor el promedio general de las calificaciones en la universidad.

## Relacion entre variables

Se grafican las variables que determinarían $colGPA$ para comparar sus distribuciones y sus pendientes ($b$) de sus respectivas regresiones simples.

```{r}
#Grafico x1 = ACT
gact <- ggscatter(gpa1, x = "ACT", y = "colGPA",
          shape = 21, size = 3, # Forma y tamaño de puntos
   add = "reg.line", #Agregar recta de regresion
   cor.coef = TRUE)# Agregar coeficiente correlacion
#Grafico x2 = hsGPA
ghsGPA <- ggscatter(gpa1, x = "hsGPA", y = "colGPA",
          shape = 21, size = 3,
   add = "reg.line",
   cor.coef = TRUE)

grid.arrange(gact, ghsGPA, nrow = 1) # Unir graficos

```

Con el gráfico anterior podemos notar que si bien ambas variables tienen una asociación positiva con $colGPA$, el tamaño efecto de esta relación es distinta. Incluso, $hsGPA$ que no había sido considerada en nuestro modelo inicial, tiene una asociación más grande con nuestra variable dependiente.
Ahora bien, ¿cómo incide $ACT$ y $hsGPA$ en conjunto sobre $colGPA$?

## Modelo de regresión multiple

Para estimar el modelo de regresión multiple se debe realizar el mismo procedimiento de la regresión simple, solo que ahora deben señalar un (+) y el segundo predictor

<div class="alert alert-info">
  <strong>Grabar / exportar tablas</strong> :<span class="sidenote">Exportar tablas </span>
modelo <- lm(y ~ x1 + x2 , data = data)
</div>

```{r}
col_actmodel<-lm(colGPA ~ ACT, data=gpa1)
col_hsmodel<-lm(colGPA ~  hsGPA, data=gpa1)
col_model <- lm(colGPA ~ ACT + hsGPA, data = gpa1)
```

```{r}
sjPlot::tab_model(list(col_actmodel, col_hsmodel,col_model), show.ci=FALSE, p.style = "asterisk", dv.labels = c("Modelo 1", "Modelo 2", "Modelo 3"),string.pred = "Predictores", string.est = "β")
```

$$\widehat{colGPA} = 1.29 +0.0094 \dot\ ACT + 0.453\dot\ hsGPA $$

## Interpretación

¿Cómo se interpreta esta ecuación general de $colGPA$ con dos predictores?

### Intercepto

- El intercepto 1.20 indica la predicción del promedio general de calificaciones en la universidad ($colGPA$) si $hsGPA$ y $ACT$ son ambos cero. Este intercepto no tiene mucho significado debido a que eso implica un individuo ficticio que no haya ni asistido a la universidad ni haya asistido a la enseñanza media, por lo cual no es parte de nuestra pregunta por las **determinantes del promedio en la universidad**.

### Coeficientes de regresion

- Fijémonos en los coeficientes de regresión de $hsGPA$. Como era de esperar en función de los gráficos que habíamos presentado, existe una relación positiva entre $hsGPA$ y $colGPA$: con $ACT$ constante, cada punto más en $hsGPA$ se relaciona con un aumento en 0.453 puntos adicionales en $colGPA$, es decir, casi medio punto.

En otras palabras, si se eligen dos estudiantes, A y B, y estos tienen la misma puntación en el exámen de admisión ($ACT$), pero el promedio en la enseñanza media de A es mayor al de B ($hsGPA$), entonces se predice que **en la universidad el estudiante A tendrá un promedio general de 0.453 puntos más altos que el estudiante B**.

- Fijémonos ahora en el coeficiente de regresión de $ACT$: si $hsGPA$ permanece constante, un aumento en un punto de $ACT$ solo  produce un aumento en 0.0094 puntos en $colGPA$, es decir, un cambio muy pequeño.

De hecho, un cambio de 10 puntos en el examen de admisión $ACT$ tendrá un efecto sobre $colGPA$ de menos de una décima de punto, es decir, menor al cambio que tiene $hsGPA$. Además, la posibilidad de tener un cambio de 10 puntos en $ACT$ es muy grande pues como mostramos en los estadísticos descriptivos de nuestras variables el promedio de puntaje en $colGPA$ es 24 puntos con una desviación estándar de 2.8, lo que hace *poco posible ese cambio en la realidad*.

Con esto podemos decir que el puntaje en el examen de admisión $ACT$ no es un fuerte predictor del promedio de calificaciones en la universidad $colGPA$.

## Comparando el modelo de regresión simple con múltiple

Iniciamos este práctico mostrando un análisis de regresión simple con un predictor para el promedio de calificaciones en la universidad: el promedio en el examen de admisión ($ACT$).

Obtuvimos que por cada punto de aumento de $ACT$, $colGPA$ aumentaba en 0.0271 puntos sus calificaciones, es decir, **casi el triple de lo que fue estimado en el modelo de regresión múltiple** (tal como se señala en Modelo 1)

¿Cuál de los dos modelos es más certero?

Esto lo podemos definir a partir de la bondad de ajuste de nuestros modelos. Por un lado, el $R^2$ del modelo  1  es de 4.3% mientras que en el modelo 3 el $R^2ajustado$ es de 16%, es decir, las variables que se contienen en el modelo explican más la varianza de nuestra variable dependiente.

## ¿Por qué utilizar R^2 ajustado?

Hasta ahora habíamos utilizado $R^2$ que nos señalaba qué porcentaje de la variación de la variable dependiente es explicada por la variable independiente.

Ahora bien, es esperable que a medida que añadimos más variables a una regresión, el $R^2$ tiende a aumentar a pesar de que la contribución de cada una de las variables nuevas no tenga relevancia estadística.

Por ello, el $R^2$ ajustado se utiliza en la regresión múltiple para analizar en conjunto la **intensidad** que tienen las variables independientes en explicar la variable dependiente. Es decir, el $R^2$  ajustado nos dice qué porcentaje de variación de la variable dependiente es explicado **colectivamente por todas las variables independientes**.

En consecuencia, $R^2$ ajustado nos permite determinar mejor si añadir una nueva variable al modelo permite explicar una mayor parte de la variación de la variable dependientE.

En el ejercicio anterior bien podemos hacer este análisis comparando los $R^2$ de nuestros modelos 1 y 2 para luego mirar el resultado de nuestro $R^2$ ajustado en nuestro modelo 3. Como podremos notar el $R^2$ del modelo 2 es de 17%, mientras que el $R^2$ es de 18% y el $R^2$ ajustado de 16%.

En palabras más simples, si solo miramos el $R^2$ llegaremos a la conclusión de que aunque por mínimo que sea, nuestro modelo 3 ajusta mejor que el modelo 2 pues la variable $ACT$ permitiría predecir mejor $colGPA$ en conjunto a $hsGPA$. Sin embargo, $R^2 ajustado$ del modelo 3 (16%) es menor que la del modelo 2 (17%) por lo que la incorporación de $ACT$ al modelo múltiple no tiene un aporte significativo.

De hecho, un punto no menor es que $ACT$ pierde significancia estadística en el modelo 3, mientras que $hsGPA$ sigue siendo significativa con un 99% confianza (**la significancia estadística lo revisaremos más adelante**).

# Resumen Práctica 5:

En esta práctica revisamos los siguientes contenidos

- Repaso de regresión lineal simple
- Estimación de regresión lineal múltiple
- Interpretar regresión lineal múltiple
- Comparar regresión múltiple y simple
- Diferencia entre $R^2$ ajustado y $R^2$


# Reporte de progreso

Completar el reporte de progreso correspondiente a esta práctica [aquí](https://forms.gle/brkQMxwLC2PRZRmr5).

# Foro práctica 5
